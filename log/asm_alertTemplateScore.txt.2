ACFSDG
AFDLIB \S+ Failed @ \S+ \S+ \S+ err=-5 \S+ \S+ \S+--0
AFDLIB \S+ Failed @ \S+ err=-5 \S+ \S+ \S+--0
AFDLIB \S+ failed to get devnum for \S+
ALTER \S+ \S+ \S+ .*
ALTER \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+
ALTER \S+ \S+ .* \(.*\).'.*'.* \(.*\).'.*'.* .* \(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ .* \(.*\).'.*'.* .* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ .* \S+ SID='.*';--0
ALTER \S+ \S+ .* SCOPE=SPFILE;
ALTER \S+ \S+ event='.*',.* \[.*\] disk highest'.*'trace \[.*\] disk highest'.*'15199 trace name context forever, level 0x4000707.*--0
ALTER \S+ \S+ listener_networks='.*','.*' SCOPE=MEMORY SID='.*';--0
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'\(.*\)'.*'.* .* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'\(.*\).* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'\(.*\).* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\).'.*'\(.*\)'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';--0
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* .* .* .*
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\).'.*'.* .* .* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*','.*',.* \(.*\)..* SCOPE=MEMORY SID='.*';--0
ALTER \S+ \S+ listener_networks='.*',.* \(.*\)\(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*',.* \(.*\).'.*'.* \(.*\)\(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*',.* \(.*\).'.*'.* \(.*\).'.*'.* \(.*\)\(.*\).'.*'.* \(.*\).'.*'.* \(.*\)..* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ listener_networks='.*',.* .* SCOPE=MEMORY SID='.*';
ALTER \S+ \S+ local_listener='.*' SCOPE=MEMORY SID='.*';--0
ARB0 started with \S+ \S+ \S+--0
ARBA started with \S+ \S+ \S+--0
ASM \S+ ./--0
ASM Health Checker found \S+ new failures--0
ASM appliance configuration detected
ASM appliance found missing disk in slot \S+
ASM instance--0
ASMB started with \S+ \S+ \S+--0
ASMCMD ./ALTER \S+ \S+ \S+ \S+ '.*' = '.*'--0
ASMCMD ./ALTER \S+ \S+ \S+  --0
ASMCMD ./ALTER \S+ \S+ \S+--0
ASMCMD ./alter diskgroup /.ASMCMD./ ".*" drop file '.*'--0
ATTRIBUTE '.*'='.*','.*'='.*','.*'='.*','.*'='.*','.*'='.*' /. \S+ ./--0
Abort recovery for domain \S+ flags \S+--0
Aborting pending dump requests \(.*\) as \S+ is shutting down
Additional information: \S+--0
Adjusting the default value of parameter \S+
All grantable enqueues granted--0
An eviction is expected due network config
Archiving is disabled--0
As it is starting up, terminate the instance.
Attached to domain \S+ \(.*\)--0
Autodiscovered Loopback ips: \S+--0
Autotune of undo retention is turned on.--0
Available system pagesizes:--0
Begin lmon rcfg omni enqueue reconfig \S+--0
Binary of new process does not match binary which started instance--0
CDB instance recovery on pdb \S+ needs to \S+ aborted \(.*\)--0
CELL communication is configured to use \S+ interface\(.*\):--0
CKPT \(.*\) waits for \S+ '.*' for \S+ secs.
CKPT started with \S+ \S+ \S+--0
CLI notifier \S+ \S+--0
CLMN started with \S+ \S+ \S+--0
CLMN: delete \S+ process - \S+
Cause - .*--0
Cell: \S+ could not \S+ opened during discovery--0
Client address: \(.*\)--0
Cluster Communication is configured to use IPs from: GPnP--0
Cluster Synchronization Service is shutting down--0
Cluster communication is configured to use the following interface\(.*\) for this instance
Cluster is in Rolling Migration, \S+ parameter not updated
Communication channels reestablished--0
Communications reconfiguration: \S+ \S+ \S+ \S+ .*
Could not connect to other instances in the cluster during startup. Hence, \S+ is terminating the instance. Please check the \S+ trace file for details. Also, please check the network logs of this instance along with clusterwide network health for problems and then re-start this instance.--0
Creating new log segment:--0
DATA0910
DATA1018
DATA1112
DATAFZA
DATAFZH_MIAO
DATAFXI
DATARHPS
DATA--0
DBW0 started with \S+ \S+ \S+--0
DB_DATA_DG
DBDG--0
DB_HOME_DG
DDE: Problem Key '.*' was completely flood controlled \(.*\)
DG04_0000 \(.*\)
DG_0930
DG_1016
DIA0 Critical Database Process As Root: Hang \S+ \S+ blocks \S+ sessions
DIA0 started with \S+ \S+ \S+--0
DIAG started with \S+ \S+ \S+--0
DISK '.*' \S+ \S+--0
DSKM process appears to \S+ hung. Initiating system state dump.
DSKM started with \S+ \S+ \S+--0
Data Pump shutdown on \S+ \S+ in progress
Dead instances \(.*\) \S+--0
Decreasing priority of \S+ \S+--0
Detect instances running with non \S+ version.
Detected change in \S+ count to \S+
Detected partial connectivity during \S+ reconfiguration.
Detected partial connectivity in the cluster during \S+
Direct \S+ channel id \[.*\] path \[.*\] to filer \[.*\] via local \[.*\] is \S+  --0
Dirty Detach Reconfiguration complete \(.*\)--0
Dirty detach reconfiguration started \(.*\)--0
Diskgroup with \S+--0
Domain name: \S+
Dump of system resources acquired for \S+ \S+ \S+ \(.*\)--0
Dumping current patch information--0
Dumping diagnostic data in directory=\[.*\], requested by \(.*\), summary=\[.*\].--0
Dumping list of patches:
Dwn-cvts replayed, VALBLKs dubious--0
ERROR: .*--100
ERROR: \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./
ERROR: \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./
ERROR: \S+ \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+--0
ERROR: \S+ \S+ \S+ \S+ \S+  SITE \S+  FAILGROUP \S+  DISK '.*' \S+ \S+--0
ERROR: \S+ \S+ \S+ \S+ \S+  SITE siteq  DISK '.*' \S+ \S+--0
ERROR: \S+ \S+ \S+ \S+  /. asm agent .//. \{.*\} ./--0
ERROR: \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+--0
ERROR: \S+ \S+ \S+ \S+  QUORUM \S+ '.*' \S+ \S+--0
ERROR: \S+ \S+ \S+ \S+  SITE siteb  DISK '.*' \S+ \S+--0
ERROR: \S+ \S+ \S+ \S+ /. asm agent call crs .//. \{.*\} ./--0
ERROR: \S+ \S+ \S+ \S+ for \S+ \S+ \(.*\)
ERROR: \S+ \S+ \S+ \S+
ERROR: \S+ \S+ \S+ set attribute '.*'='.*'
ERROR: \S+ \S+ csdg \S+ \S+  SITE sitea  FAILGROUP \S+  DISK '.*' \S+ ted1  SIZE \S+--0
ERROR: \S+ \S+ tst \S+ \S+  DISK '.*' \S+ \S+--0
ERROR: \S+ could not check any \S+ heartbeat \(.*\)
ERROR: \S+ failed to obtain \S+ global quorum of supporting sites in group \S+ \(.*\)--0
ERROR: \S+ in \S+ recovery for diskgroup \S+ \(.*\)--0
ERROR: \S+ terminating the instance due to storage split in grp \S+--0
ERROR: \S+ thrown in \S+ for group number \S+--0
ERROR:  ALTER \S+ \S+ \S+
ERROR: /. \S+ ./ALTER \S+ \S+ \S+--0
ERROR: /. \S+ ./alter diskgroup \S+ \S+ volume '.*' size \S+
ERROR: /. \S+ ./alter diskgroup \S+ drop volume '.*'
ERROR: /. \S+ ./alter diskgroup /.ASMCMD./ ".*" drop file '.*'--0
ERROR: /. Exadata Auto Mgmt: \S+ \S+ Disk ./--0
ERROR: Could not \S+ \S+ for grp \S+ Force dismounting the disk group.--0
ERROR: Failed to cleanup the \S+ stale FDs--0
ERROR: No disks with \S+ found on disk group \S+--0
ERROR: Rolling Migration Modules/Privilaged Operations returned failure. Module code = \S+ error value = \S+
ERROR: Shared memory area is accessible to instance startup process--0
ERROR: Unable to get logical block size for spfile '.*'.--0
ERROR: Voting file allocation failed for group \S+
ERROR: alter diskgroup \S+ \S+ disk '.*' force--0
ERROR: alter diskgroup \S+ \S+ site \S+ disk '.*' force--0
ERROR: alter diskgroup \S+ \S+--0
ERROR: alter diskgroup \S+ dismount force /. \S+ \S+ ./--0
ERROR: alter diskgroup \S+ dismount--0
ERROR: alter diskgroup \S+ drop disk \S+ force /. \S+ \S+ ./--0
ERROR: alter diskgroup \S+ drop volume \S+ /. \S+ ./
ERROR: alter diskgroup \S+ online disk .*--0
ERROR: alter diskgroup \S+ online disk '.*' force--0
ERROR: alter diskgroup \S+ rebalance--0
ERROR: alter diskgroup data \S+ site sitea disk '.*'--0
ERROR: alter diskgroup data \S+ site siteb disk '.*' force--0
ERROR: alter diskgroup data \S+ site siteb disk '.*'--0
ERROR: alter diskgroup data online disk .*--0
ERROR: alter diskgroup data online disk '.*' force--0
ERROR: alter diskgroup sudg rebalance--0
ERROR: alter diskgroup vfdg \S+ disk '.*' name \S+ force--0
ERROR: alter diskgroup vfdg \S+ site siteb disk '.*' name ted04 force--0
ERROR: alter diskgroup vfdg \S+ site siteb disk '.*' name ted04--0
ERROR: alter diskgroup vfdg online disk '.*'--0
ERROR: disk \S+ \(.*\) in group \S+ \(.*\) cannot \S+ offlined because all disks \[.*\] with mirrored data would \S+ offline.--0
ERROR: disk 0\(.*\) in group .* cannot \S+ offlined because the disk group has external redundancy.--0
ERROR: diskgroup \S+ was not \S+--0
ERROR: failed to  diskgroup resource \S+
ERROR: group \S+ \(.*\): could not validate disk \S+--0
ERROR: no read quorum in group: required \S+ found \S+ disks--0
ERROR: too many offline disks in \S+ \(.*\)--0
ERROR: updating header of disk \S+ with voting file information--0
End lmon rcfg omni enqueue reconfig \S+--0
Error \S+ Cluster Synchronization Service is shutting down--0
Error \S+ requesting async resources
Error \S+ unexpected return code \S+ from the Cluster Synchronization \S+--0
Error attempting to elevate .*
Error: Shutdown in progress. Error: \S+--0
Error: received an \S+ event from the Cluster Synchronization Service--0
Errors in file \S+  \(.*\):--0
Errors in file \S+--0
Evicting instance \S+ from cluster--0
Exadata Auto Mgmt: \S+ \S+ Disk ./--0
Exadata cell: \S+ is no longer accessible. I/O errors to disks on this might get suppressed--0
Exadata error:'.*'--0
Exception \[.*\] \[.*\] \[.*\] \[.*\]--0
Execute glob on the string \S+--0
Expected per process system memlock \(.*\) limit to lock--0
Expecting \S+ \S+ instances to leave the cluster.--0
FLASH
FLEXDGB
Fatal \S+ connect error \S+ connecting to:--0
Fatal \S+ connect error \S+--0
Final blocker is session \S+ \S+ serial# \S+ \S+ \S+ on Instance \S+
Fix write in gcs resources--0
Following system state dump requests \(.*\) will \S+ processed:--0
Fri \S+ \S+ \S+ \S+
Further messages for this problem key will \S+ suppressed for up to \S+ minutes
GCR0\[.*\]: \S+ \S+ process is not making progress for \S+ secs--0
GCR0\[.*\]: \S+ process is not making progress for \S+ secs, trying to restart it--0
GCR0\[.*\]: \S+ process succesfully killed--0
GCR0 \(.*\) is blocking \S+ \(.*\) in \S+ wait
GEN0 started with \S+ \S+ \S+--0
GEN1 started with \S+ \S+ \S+--0
GHDG
GIDG_FXCFXD_0516
GIDG
GMON \(.*\): terminating the instance due to error \S+--0
GMON \S+ group \S+ at \S+ for pid \S+ osid \S+
GMON checking disk \S+ for group \S+ at \S+ for pid \S+ osid \S+
GMON dismounting group \S+ at \S+ for pid \S+ osid \S+--0
GMON dumping for group \S+--0
GMON dumping for group - Done--0
GMON querying group \S+ at \S+ for pid \S+ osid \S+--0
GMON started with \S+ \S+ \S+--0
GMON updating disk modes for group \S+ at \S+ for pid \S+ osid \S+--0
GMON updating for reconfiguration, group \S+ at \S+ for pid \S+ osid \S+--0
GMON updating group \S+ at \S+ for pid \S+ osid \S+--0
Global Resource Directory frozen--0
Global Resource Directory partially frozen for dirty detach--0
Got error \S+ from ksusig, cleared
High Throughput Write functionality enabled--0
ILAT =0
IM on \S+ \S+ of Empty Journal
IMODE=\S+
IMR has experienced some problems and can.*--0
IMR has experienced some problems during thread mount, \(.*\)--0
IMR0 \(.*\) waits for event '.*' for \S+ secs.--0
IO elapsed time: \S+ usec Time waited on I/O: \S+ usec--0
IP: \S+ Subnet: \S+--0
IPC Send timeout detected. Sender: ospid \S+ \[.*\]--0
IPC Send timeout to \S+ inc \S+ for msg type \S+ from opid \S+--0
IPC Send timeout: Terminating pid \S+ osid \S+--0
IPC Vendor \S+ proto \S+--0
If resolvable, instance eviction will \S+ attempted by Hang Manager
Incident details in: \S+--0
Increasing priority of \S+ \S+--0
Initial number of \S+ is \S+--0
Instance \S+ interface \[.*\] are not pingable.
Instance Critical Process \(.*\) died unexpectedly--0
Instance reconfiguration: current system load \S+ \(.*\)
Instance shutdown cancelled--0
Instance shutdown complete \(.*\)--0
Instance terminated by \S+ pid = \S+--0
Instances w/ version \S+ \S+ \S+ \S+ \S+
Instances w/ version \S+ \S+ \S+ \S+
Instances w/ version \S+ \S+ \S+
KSIPC \S+ \S+--0
KSIPC Available Transports: \S+--0
KSIPC Loopback \S+ addresses\(.*\):--0
KSIPC: Client: \S+ Transport: \S+--0
KSXP: \S+ \S+ \S+--0
KSXP: setting socket save mode to \S+--0
KSXPPING: \S+ selected for Ping--0
KSXRTEST \S+ \S+ \S+ \S+ = \S+
LCK0 \(.*\) received unexpected status \(.*\) from the Cluster Synchronization Service.--0
LCK0 started with \S+ \S+ \S+--0
LCK1 started with \S+ \S+ \S+--0
LGWR \(.*\) waits for event '.*' for \S+ secs.--0
LGWR started with \S+ \S+ \S+--0
LICENSE_MAX_SESSION = \S+--0
LICENSE_MAX_USERS = \S+--0
LICENSE_SESSIONS_WARNING = \S+--0
LMD0 \(.*\) has detected no messaging activity from instance \S+--0
LMD0 \(.*\): terminating the instance due to \S+ error \S+
LMD0 \(.*\): terminating the instance due to error \S+--0
LMD0 started with \S+ \S+ \S+--0
LMHB \(.*\) kills \S+ \(.*\).
LMHB \(.*\): terminating the instance due to error \S+--0
LMHB started with \S+ \S+ \S+--0
LMON \(.*\) detects hung instances during \S+ reconfiguration
LMON \(.*\) drops the \S+ request from \S+ \(.*\) because \S+ is in progress and inst \S+ is marked bad.--0
LMON \(.*\) tries to kill the instance \S+ in \S+ seconds.
LMON \(.*\): terminating the instance due to \S+ error \S+
LMON \(.*\): terminating the instance--0
LMON received an instance eviction notification from instance \S+--0
LMON started with \S+ \S+ \S+--0
LMS \S+ \S+ \S+ shadows cancelled, \S+ closed, \S+ Xw survived, skipped \S+--0
LMS \S+ \S+ \S+ shadows cancelled, \S+ closed, \S+ Xw survived
LMS0 \(.*\) has detected no messaging activity from instance \S+--0
LMS0 started with \S+ \S+ \S+ at elevated \(.*\) priority--0
LMS0 started with \S+ \S+ \S+
LREG started with \S+ \S+ \S+--0
License high water mark = \S+--0
Linux-x86_64 Error: \S+ Input/output error--0
Linux-x86_64 Error: \S+ No such file or directory--0
List of instances \(.*\) \S+--0
Load Monitor used for high load check--0
Loopback ip: \S+--0
MARK started with \S+ \S+ \S+--0
MEMORY_TARGET defaulting to \S+--0
MGMT1112
MGMT_EXTERNAL
MGMT_NORMAL
MGMT--0
MMDG
MMAN started with \S+ \S+ \S+--0
MMNL started with \S+ \S+ \S+--0
MMON started with \S+ \S+ \S+--0
Machine:	x86_64--0
Master broadcasted resource hash value bitmaps--0
Mon Oct \S+ \S+ \S+
My inst \S+ .*--0
NOTE: .*--0
NOTE: \S+ \(.*\) connected to \S+ instance \S+ osid: \S+ \(.*\)--0
NOTE: \S+ \S+ \S+ \S+ for \S+ \S+ \(.*\)--0
NOTE: \S+ \S+ \S+ copy \S+ relocating from \S+ to \S+ at \S+ \S+--0
NOTE: \S+ \S+ \S+ found on disk \S+ au \S+ fcn \S+ datfmt \S+--0
NOTE: \S+ about to begin recovery lock claims for diskgroup \S+ \(.*\)--0
NOTE: \S+ attempting to mount thread \S+ for diskgroup \S+ \(.*\)--0
NOTE: \S+ clearing idle groups before exit--0
NOTE: \S+ client \S+ disconnected unexpectedly.--0
NOTE: \S+ closing thread \S+ of diskgroup \S+ \(.*\) at \S+ \S+--0
NOTE: \S+ connected to \S+ instance \S+ osid: \S+ \(.*\)
NOTE: \S+ detected lock domain \S+ invalid at system inc \S+ \S+ \S+--0
NOTE: \S+ did \S+ \S+ recovery for group \S+ \(.*\)--0
NOTE: \S+ did instance recovery for group \S+ domain \S+--0
NOTE: \S+ doing \S+ dismount of group \S+ \(.*\) thread \S+--0
NOTE: \S+ expansion required for disk group \S+--0
NOTE: \S+ fcn on disk \S+ synced at fcn \S+--0
NOTE: \S+ found thread \S+ closed at \S+ \S+ lock \S+ \S+ \S+--0
NOTE: \S+ has subscribed--0
NOTE: \S+ heartbeating for grp \S+ \(.*\)--0
NOTE: \S+ instance \S+ cleaned prior client \S+ as requested
NOTE: \S+ mc1 Node Registration \S+ suceeded
NOTE: \S+ not being messaged to dismount--0
NOTE: \S+ on disk \S+ \(.*\) relocated at fcn \S+ \S+ \S+ -> \S+ \S+--0
NOTE: \S+ opened thread \S+ \(.*\) at fcn \S+ \S+ \S+ lock \S+ \S+ \S+ \S+ \S+ \S+--0
NOTE: \S+ process exiting due to \S+ instance shutdown \(.*\)--0
NOTE: \S+ process exiting due to lack of \S+ file activity for \S+ seconds--0
NOTE: \S+ process exiting, either shutdown is in progress or foreground connected to \S+ was killed.--0
NOTE: \S+ recovery sucessfully read \S+ from one mirror side--0
NOTE: \S+ registering with \S+ instance as Standard client \S+ \(.*\) \(.*\)--0
NOTE: \S+ released recovery enqueue for thread \S+ group \S+ \(.*\)--0
NOTE: \S+ requested to fence Remote cluster client \S+ id \S+
NOTE: \S+ requested to fence client \S+ id \S+ \S+--0
NOTE: \S+ skipping disk \S+ \(.*\)--0
NOTE: \S+ skipping lock domain \(.*\) validation because diskgroup being dismounted--0
NOTE: \S+ skipping lock domain validation because relocation enqueue was busy and the threads are not closed yet
NOTE: \S+ starting instance recovery of group \S+ domain \S+ inc \S+ \(.*\) at \S+ \S+--0
NOTE: \S+ successfully validated lock domain \S+ inc \S+ \(.*\)--0
NOTE: \S+ successfully wrote to at least one mirror side--0
NOTE: \S+ sync \S+ last written \S+ \S+--0
NOTE: \S+ update grp = \S+ completed successfully--0
NOTE: \S+ validation of lock domain \S+ failed \(.*\)--0
NOTE: \S+ waiting for thread \S+ recovery enqueue--0
NOTE: \S+ will attempt offline of disk \S+ - no header--0
NOTE: \[.*\] \S+ \S+ file \S+ osid \S+--0
NOTE: \[.*\] opening \S+ file \S+
NOTE: 03/23/16 \S+ \S+ copy \S+ relocating from \S+ to \S+ at \S+ \S+--0
NOTE: Active use of \S+ in group \S+--0
NOTE: Adding disk \S+ \(.*\) to grp \S+ \(.*\) \(.*\)--0
NOTE: Advanced to new \S+ format for group \S+--0
NOTE: Advancing \S+ compatibility to \S+ for grp \S+--0
NOTE: Appliance mode enabled for grp \S+
NOTE: Assigning number \(.*\) to disk \(.*\)--0
NOTE: Attempting voting file \S+ \S+ diskgroup \S+--0
NOTE: Cleaning \S+ Remote Cluster client \S+ id \S+
NOTE: Cleaning up fence pending client id \S+ \[.*\] \(.*\) \[.*\]--0
NOTE: Cluster configuration type = \S+ \[.*\]--0
NOTE: Cluster is in Rolling \S+
NOTE: Cluster is in Rolling Migration from \S+ to \S+
NOTE: Completed marking of \S+ resync flags for group \S+ \(.*\)
NOTE: Created Used Space Directory for \S+ threads--0
NOTE: Created Virtual Allocation Locator \(.*\) and Table \(.*\) directories for group \S+ \(.*\)--0
NOTE: Creating voting files in diskgroup: \S+--0
NOTE: DRTimer \S+ Create:  for disk group \S+ disks:
NOTE: DRTimer \S+ Destroy: for diskgroup \S+
NOTE: Deferred communication with \S+ instance--0
NOTE: Deleting voting files in diskgroup \S+--0
NOTE: Disk \S+ in \S+ \S+ \S+ \S+ \S+--0
NOTE: Diskgroup used for \S+ \S+ \S+--0
NOTE: Diskgroup used for \S+ \S+--0
NOTE: Diskgroups listed in \S+ are--0
NOTE: Erasing header on \S+--0
NOTE: Expelling disk \S+ \(.*\) from grp \S+ \(.*\)
NOTE: Extended the Used Space Directory to thread \S+--0
NOTE: Failed voting file relocation on diskgroup \S+--0
NOTE: Fenced Remote Cluster client \S+ id \S+
NOTE: Flex Remote Cluster client \S+ \S+ osid \S+ mbr \S+ asmb \S+ \(.*\)
NOTE: Flex Remote Cluster client id \S+ \[.*\] attempting to \S+
NOTE: Flex client \S+ \S+ osid \S+ mbr \S+ asmb \S+ \(.*\)--0
NOTE: Flex client id \S+ \[.*\] attempting to \S+--0
NOTE: Found \S+ for disk \S+--0
NOTE: GroupBlock outside rolling migration privileged region--0
NOTE: Instance updated \S+ to \S+ for grp \S+ \(.*\).--0
NOTE: Instance updated compatible.asm to \S+ for grp \S+
NOTE: Loaded library: \S+
NOTE: No voting file found on diskgroup \S+--0
NOTE: Notify \S+ to check and update diskgroup resource state
NOTE: PatchLevel of this instance \S+--0
NOTE: Physical metadata for diskgroup \S+ \(.*\) was replicated.--0
NOTE: Proactively cleaning up \S+ client \S+ with orphan ownerid \S+ \S+ elapsed--0
NOTE: Quantized compatibility from \S+ to \S+
NOTE: Refresh completed on diskgroup \S+ \S+ \S+ \S+ .*--0
NOTE: Refresh completed on diskgroup \S+
NOTE: Remote Cluster client \S+ id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: Shutting down \S+ background process--0
NOTE: Standard client \S+ registered, osid \S+ mbr \S+ asmb \S+ \(.*\)--0
NOTE: Started marking of \S+ resync flags for group \S+ \(.*\)
NOTE: Starting expel slave for group \S+ \(.*\)--0
NOTE: Starting resync using Staleness Registry and \S+ scan for group \S+
NOTE: Submit AFDLIB:AFD_KEYS\(.*\)--0
NOTE: Successful voting file relocation on diskgroup \S+--0
NOTE: Suppressing further \S+ \S+ errors on \S+ \S+--0
NOTE: Termination of \S+ session succeeded for \[.*\] due to instance shutdown--0
NOTE: The rdbms compatibility of group \S+ is \S+--0
NOTE: This instance is the master for audit cleanup--0
NOTE: Trace records dumped in trace file \S+--0
NOTE: Using GPnP to retrieve the \S+ password file location in exclusive mode--0
NOTE: Using default \S+ root directory \S+
NOTE: Volume support  enabled--0
NOTE: Voting File refresh pending for group \S+ \(.*\)--0
NOTE: Voting file relocation is required in diskgroup \S+--0
NOTE: Waiting for privileged operations to complete
NOTE: aborting instance recovery of domain \S+ due to diskgroup dismount--0
NOTE: advancing ckpt for group \S+ \(.*\) \S+ \S+ domain inc# \S+--0
NOTE: allocating \S+ \(.*\) on grp \S+ disk \S+--0
NOTE: allocating \S+ on grp \S+ disk \S+--0
NOTE: already refreshed membership for group 1/0x8e10855f \(.*\)--0
NOTE: assigning \S+ to group \S+ \(.*\) to compute estimates--0
NOTE: assigning \S+ to group \S+ \(.*\) with \S+ parallel \S+
NOTE: attached to recovery domain \S+--0
NOTE: blocked Flex client \S+ registered, osid \S+ mbr \S+ asmb \S+ \(.*\)--0
NOTE: cache began mount \(.*\) of group \S+ \S+--0
NOTE: cache closing disk \S+ of grp \S+ .*--0
NOTE: cache closing disk \S+ of grp \S+ \(.*\) \S+--0
NOTE: cache creating group \S+ \(.*\)--0
NOTE: cache deleting context for group \S+ \S+--0
NOTE: cache dismounted group \S+ \(.*\)--0
NOTE: cache dismounting \(.*\) group \S+ \(.*\)--0
NOTE: cache ending mount \(.*\) of group \S+ \S+ \S+--0
NOTE: cache initiating offline of disk \S+ group \S+--0
NOTE: cache is mounting group \S+ created on \S+ \S+--0
NOTE: cache mounting \(.*\) \S+ redundancy group \S+ \(.*\)--0
NOTE: cache mounting group \S+ \(.*\) succeeded--0
NOTE: cache opening disk \S+ of grp \S+ \S+ \S+--0
NOTE: cache recovered group \S+ to fcn \S+--0
NOTE: cache registered group \S+ \S+--0
NOTE: check client alert log.--0
NOTE: checking \S+ consistency for diskgroup \S+
NOTE: checking \S+ for grp \S+ done.--0
NOTE: checking \S+ grp = \S+--0
NOTE: checking file group consistency for diskgroup \S+
NOTE: cleaned up \S+ client \S+ connection state \(.*\)--0
NOTE: cleaned up \S+ client \S+ connection state--0
NOTE: cleaned up \S+ client dbs12:dbs1:rws00fzwfzx connection state \(.*\)
NOTE: cleaned up \S+ client dbs12:dbs1:rws00fzwfzx connection state
NOTE: cleaning stale placeholder for closed file \(.*\) after 300s, in client \S+
NOTE: cleaning stale remote ownerid \S+ for client \S+ \(.*\)--0
NOTE: cleaning up empty system-created directory '.*'--0
NOTE: client \S+ .*--0
NOTE: client \S+ \S+ \S+ \S+ .*
NOTE: client \S+ fence duration: \S+ seconds--0
NOTE: client \S+ id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced--0
NOTE: client \S+ is exiting--0
NOTE: client \S+ mounted group \S+ \(.*\)--0
NOTE: client \S+ no longer has group \S+ \(.*\) mounted--0
NOTE: client \S+ should failover--0
NOTE: client \[.*\] completed disk validation \(.*\)--0
NOTE: client \[.*\] declared \S+ additional pending writes--0
NOTE: client .ASM:asmvol deregistered
NOTE: client .ASM:asmvol no longer has group \S+ \(.*\) mounted
NOTE: client .IOS1:.IOS:rws-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client .IOS1:.IOS:rws-cluster mounted group \S+ \(.*\)
NOTE: client .IOS1:.IOS:rwssn0607-clu id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client .IOS1:.IOS:slcc04d-cluster fence duration: \S+ seconds
NOTE: client .IOS1:.IOS:slcc04d-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client .IOS1:.IOS:slcc04d-cluster should failover
NOTE: client .IOS2:.IOS:rws-cluster mounted group \S+ \(.*\)
NOTE: client .IOS2:.IOS:rwssn0607-clu id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client .IOS2:.IOS:slcc04d-cluster fence duration: \S+ seconds
NOTE: client .IOS6:.IOS:rws-cluster mounted group \S+ \(.*\)
NOTE: client Ase12:Ase12:scaoda7m004-c deregistered
NOTE: client Ase12:Ase12:scaoda7m004-c mounted group \S+ \(.*\)
NOTE: client E1:E:scaoda704c1n1-c deregistered
NOTE: client E1:E:scaoda704c1n1-c fence duration: \S+ seconds
NOTE: client E1:E:scaoda704c1n1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client E1:E:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client E2:E:scaoda704c1n1-c deregistered
NOTE: client E2:E:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client EXDB05271:EXDB0527:nshc01a-dsc deregistered--0
NOTE: client EXDB05271:EXDB0527:nshc01a-dsc id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced--0
NOTE: client Iib1:Iib:scaoda704c1n1-c deregistered
NOTE: client Iib1:Iib:scaoda704c1n1-c fence duration: \S+ seconds
NOTE: client Iib1:Iib:scaoda704c1n1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client Iib1:Iib:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client Iib1:Iib:scaoda704c1n1-c no longer has group \S+ \(.*\) mounted
NOTE: client Iib2:Iib:scaoda704c1n1-c deregistered
NOTE: client Iib2:Iib:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client Jn1:Jn:scoada709-c deregistered
NOTE: client Jn1:Jn:scoada709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client Jn1:Jn:scoada709-c mounted group \S+ \(.*\)
NOTE: client Jn2:Jn:scoada709-c deregistered
NOTE: client Jn2:Jn:scoada709-c mounted group \S+ \(.*\)
NOTE: client TESTDB1:TESTDB:rwsad-cluster deregistered
NOTE: client TESTDB1:TESTDB:rwsad-cluster fence duration: \S+ seconds
NOTE: client TESTDB1:TESTDB:rwsad-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client TESTDB1:TESTDB:rwsad-cluster mounted group \S+ \(.*\)
NOTE: client TESTDB2:TESTDB:rwsad-cluster fence duration: \S+ seconds
NOTE: client TESTDB2:TESTDB:rwsad-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client TESTDB2:TESTDB:rwsad-cluster mounted group \S+ \(.*\)
NOTE: client TESTDB3:TESTDB:rwsad-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client TESTDB3:TESTDB:rwsad-cluster mounted group \S+ \(.*\)
NOTE: client TESTDB4:TESTDB:rwsad-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client TESTDB4:TESTDB:rwsad-cluster mounted group \S+ \(.*\)
NOTE: client aa1:aa:scaoda709-c deregistered
NOTE: client aa1:aa:scaoda709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client aa1:aa:scaoda709-c mounted group \S+ \(.*\)
NOTE: client aa2:aa:scaoda709-c deregistered
NOTE: client aa2:aa:scaoda709-c mounted group \S+ \(.*\)
NOTE: client cdb21:cdb2:scaoda709-c deregistered
NOTE: client cdb21:cdb2:scaoda709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client cdb21:cdb2:scaoda709-c mounted group \S+ \(.*\)
NOTE: client cdb22:cdb2:scaoda709-c deregistered
NOTE: client cdb22:cdb2:scaoda709-c mounted group \S+ \(.*\)
NOTE: client cdbacfs1:cdbacfs:scaoda709-c deregistered
NOTE: client cdbacfs1:cdbacfs:scaoda709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db11:db1:rws00fxwfxx \S+ \S+ \S+ .*
NOTE: client db11:db1:rws00fxwfxx deregistered
NOTE: client db11:db1:rws00fxwfxx no longer has group \S+ \(.*\) mounted
NOTE: client db11:db1:rws00fz-cluster deregistered
NOTE: client db11:db1:rws00fz-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db11:db1:rws00fz-cluster mounted group \S+ \(.*\)
NOTE: client db11:db1:rws00fz-cluster no longer has group \S+ \(.*\) mounted
NOTE: client db11:db1:scaoda704c1n1-c deregistered
NOTE: client db11:db1:scaoda704c1n1-c fence duration: \S+ seconds
NOTE: client db11:db1:scaoda704c1n1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db11:db1:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client db121021:db12102:rwsad1112 deregistered
NOTE: client db121021:db12102:rwsad1112 id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db121021:db12102:rwsad1112 mounted group \S+ \(.*\)
NOTE: client db122:dbuser:scaoda7m004-c deregistered
NOTE: client db122:dbuser:scaoda7m004-c mounted group \S+ \(.*\)
NOTE: client db122SE:sysman:scaoda7m004-c deregistered
NOTE: client db122SE:sysman:scaoda7m004-c mounted group \S+ \(.*\)
NOTE: client db122ee:dbee:scaoda7m004-c deregistered
NOTE: client db122ee:dbee:scaoda7m004-c mounted group \S+ \(.*\)
NOTE: client db12:db1:rws00fxwfxx \S+ \S+ \S+ .*
NOTE: client db12:db1:rws00fz-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db12:db1:rws00fz-cluster mounted group \S+ \(.*\)
NOTE: client db12:db1:scaoda704c1n1-c deregistered
NOTE: client db12:db1:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client db2081:db208:scaoda710c1-c deregistered
NOTE: client db2081:db208:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db2081:db208:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2081:db208:scaoda710c1-c no longer has group \S+ \(.*\) mounted
NOTE: client db2082:db208:scaoda710c1-c deregistered
NOTE: client db2082:db208:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2101:db210:scaoda710c1-c deregistered
NOTE: client db2101:db210:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db2101:db210:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2101:db210:scaoda710c1-c no longer has group \S+ \(.*\) mounted
NOTE: client db2102:db210:scaoda710c1-c deregistered
NOTE: client db2102:db210:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db216:db216:scaoda710c1-c deregistered
NOTE: client db216:db216:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db216:db216:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db218:db218:scaoda710c1-c deregistered
NOTE: client db218:db218:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db218:db218:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2201:db220:scaoda710c1-c deregistered
NOTE: client db2201:db220:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db2201:db220:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2202:db220:scaoda710c1-c deregistered
NOTE: client db2202:db220:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2221:db222:scaoda710c1-c deregistered
NOTE: client db2221:db222:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db2221:db222:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2222:db222:scaoda710c1-c deregistered
NOTE: client db2222:db222:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db228:db228:scaoda710c1-c deregistered
NOTE: client db228:db228:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db228:db228:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db230:db230:scaoda710c1-c deregistered
NOTE: client db230:db230:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db230:db230:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2321:db232:scaoda710c1-c deregistered
NOTE: client db2321:db232:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db2321:db232:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db2322:db232:scaoda710c1-c deregistered
NOTE: client db2322:db232:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3021:db302:scaoda710c1-c deregistered
NOTE: client db3021:db302:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db3021:db302:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3022:db302:scaoda710c1-c deregistered
NOTE: client db3022:db302:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3041:db304:scaoda710c1-c deregistered
NOTE: client db3041:db304:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db3041:db304:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3042:db304:scaoda710c1-c deregistered
NOTE: client db3042:db304:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db310:db310:scaoda710c1-c deregistered
NOTE: client db310:db310:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db310:db310:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db312:db312:scaoda710c1-c deregistered
NOTE: client db312:db312:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db312:db312:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3141:db314:scaoda710c1-c deregistered
NOTE: client db3141:db314:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db3141:db314:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3142:db314:scaoda710c1-c deregistered
NOTE: client db3142:db314:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3161:db316:scaoda710c1-c deregistered
NOTE: client db3161:db316:scaoda710c1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client db3161:db316:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client db3161:db316:scaoda710c1-c no longer has group \S+ \(.*\) mounted
NOTE: client db3162:db316:scaoda710c1-c deregistered
NOTE: client db3162:db316:scaoda710c1-c mounted group \S+ \(.*\)
NOTE: client dbrac1221:dbrac12201:rwsad1112 deregistered
NOTE: client dbrac1221:dbrac12201:rwsad1112 id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client dbrac1221:dbrac12201:rwsad1112 mounted group \S+ \(.*\)
NOTE: client dbrac1222:dbrac12201:rwsad1112 deregistered
NOTE: client dbrac1222:dbrac12201:rwsad1112 id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client dbrac1222:dbrac12201:rwsad1112 mounted group \S+ \(.*\)
NOTE: client dbrac1222:dbrac12201:rwsad1112 should failover
NOTE: client dbs11:dbs1:rws00fzwfzx \S+ \S+ \S+ .*
NOTE: client dbs11:dbs1:rws00fzwfzx deregistered
NOTE: client dbs11:dbs1:rws00fzwfzx should failover
NOTE: client dbs12:dbs1:rws00fzwfzx mounted group \S+ \(.*\)
NOTE: client dbs12:dbs1:rws00fzwfzx should failover
NOTE: client e4jnfb:JLv48ZRqQ3e:scaoda704c1n1-c deregistered
NOTE: client e4jnfb:JLv48ZRqQ3e:scaoda704c1n1-c fence duration: \S+ seconds
NOTE: client e4jnfb:JLv48ZRqQ3e:scaoda704c1n1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client e4jnfb:JLv48ZRqQ3e:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client flash11:flash1:scaoda709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client flash11:flash1:scaoda709-c mounted group \S+ \(.*\)
NOTE: client flash12:flash1:scaoda709-c deregistered
NOTE: client flash12:flash1:scaoda709-c mounted group \S+ \(.*\)
NOTE: client flash21:flash2:scaoda709-c deregistered
NOTE: client flash21:flash2:scaoda709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client flash21:flash2:scaoda709-c mounted group \S+ \(.*\)
NOTE: client flash21:flash2:scoada709-c deregistered
NOTE: client flash21:flash2:scoada709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client flash21:flash2:scoada709-c mounted group \S+ \(.*\)
NOTE: client flash21:flash2:scoada709-c no longer has group \S+ \(.*\) mounted
NOTE: client flash22:flash2:scaoda709-c mounted group \S+ \(.*\)
NOTE: client flash22:flash2:scoada709-c deregistered
NOTE: client flash22:flash2:scoada709-c mounted group \S+ \(.*\)
NOTE: client gui1:gui:x701-c deregistered
NOTE: client gui1:gui:x701-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client gui1:gui:x701-c mounted group \S+ \(.*\)
NOTE: client gui2:gui:x701-c deregistered
NOTE: client gui2:gui:x701-c mounted group \S+ \(.*\)
NOTE: client mPxtUgZ1:mPxtUgZ:scoada709-c deregistered
NOTE: client mPxtUgZ1:mPxtUgZ:scoada709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client mPxtUgZ1:mPxtUgZ:scoada709-c mounted group \S+ \(.*\)
NOTE: client mPxtUgZ2:mPxtUgZ:scoada709-c deregistered
NOTE: client mPxtUgZ2:mPxtUgZ:scoada709-c mounted group \S+ \(.*\)
NOTE: client n4qrtJ2C:o7hK0agQD:scaoda704c1n1-c deregistered
NOTE: client n4qrtJ2C:o7hK0agQD:scaoda704c1n1-c fence duration: \S+ seconds
NOTE: client n4qrtJ2C:o7hK0agQD:scaoda704c1n1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client n4qrtJ2C:o7hK0agQD:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client newdb1:newdb:rws-cluster deregistered
NOTE: client newdb1:newdb:rws-cluster mounted group \S+ \(.*\)
NOTE: client newdb1:newdb:rws-cluster no longer has group \S+ \(.*\) mounted
NOTE: client rac1811:rac181:rwsad1112 id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client rac1811:rac181:rwsad1112 mounted group \S+ \(.*\)
NOTE: client rac1812:rac181:rwsad1112 deregistered
NOTE: client rac1812:rac181:rwsad1112 id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client rac1812:rac181:rwsad1112 mounted group \S+ \(.*\)
NOTE: client racdb1:racdb:rws00fz-cluster deregistered
NOTE: client racdb1:racdb:rws00fz-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client racdb1:racdb:rws00fz-cluster mounted group \S+ \(.*\)
NOTE: client racdb1:racdb:rws00fz-cluster no longer has group \S+ \(.*\) mounted
NOTE: client racdb2:racdb:rws00fz-cluster mounted group \S+ \(.*\)
NOTE: client racdb3:racdb:rws00fz-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client racdb3:racdb:rws00fz-cluster mounted group \S+ \(.*\)
NOTE: client racdb4:racdb:rws00fz-cluster fence duration: \S+ seconds
NOTE: client racdb4:racdb:rws00fz-cluster id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client racdb4:racdb:rws00fz-cluster mounted group \S+ \(.*\)
NOTE: client test11:test1:x701-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client test12:test1:x701-c deregistered
NOTE: client test12:test1:x701-c mounted group \S+ \(.*\)
NOTE: client test3:test3:scaoda709-c deregistered
NOTE: client test3:test3:scaoda709-c mounted group \S+ \(.*\)
NOTE: client testcdb1:testcdb:scaoda709-c deregistered
NOTE: client testcdb1:testcdb:scaoda709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client testdb1:testdb:scoada709-c deregistered
NOTE: client testdb1:testdb:scoada709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client testdb1:testdb:scoada709-c mounted group \S+ \(.*\)
NOTE: client testdb2:testdb:scoada709-c deregistered
NOTE: client testdb2:testdb:scoada709-c mounted group \S+ \(.*\)
NOTE: client testf1:testf:x701-c deregistered
NOTE: client testf1:testf:x701-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client testf1:testf:x701-c mounted group \S+ \(.*\)
NOTE: client testf2:testf:x701-c deregistered
NOTE: client testf2:testf:x701-c mounted group \S+ \(.*\)
NOTE: client testz:testz:scaoda7m004-c deregistered
NOTE: client testz:testz:scaoda7m004-c mounted group \S+ \(.*\)
NOTE: client xan6LztH1:QRVTZdirP:scaoda704c1n1-c deregistered
NOTE: client xan6LztH1:QRVTZdirP:scaoda704c1n1-c fence duration: \S+ seconds
NOTE: client xan6LztH1:QRVTZdirP:scaoda704c1n1-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client xan6LztH1:QRVTZdirP:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client xan6LztH2:QRVTZdirP:scaoda704c1n1-c deregistered
NOTE: client xan6LztH2:QRVTZdirP:scaoda704c1n1-c mounted group \S+ \(.*\)
NOTE: client zPkHO8J1:zPkHO8J:scoada709-c deregistered
NOTE: client zPkHO8J1:zPkHO8J:scoada709-c id \S+ has reconnected to \S+ inst \S+ \(.*\), or has been fenced
NOTE: client zPkHO8J1:zPkHO8J:scoada709-c mounted group \S+ \(.*\)
NOTE: client zPkHO8J2:zPkHO8J:scoada709-c deregistered
NOTE: client zPkHO8J2:zPkHO8J:scoada709-c mounted group \S+ \(.*\)
NOTE: closing \S+ for group: \S+--0
NOTE: completed disk validation for \S+ \(.*\)--0
NOTE: completed online of disk group \S+ disks--0
NOTE: crash recovery of group \S+ will recover \S+ \S+ \S+ \S+ \S+--0
NOTE: dbwr not being msg.*--0
NOTE: deferred map free for map id \S+--0
NOTE: detached from domain \S+--0
NOTE: detected orphaned client id \S+--0
NOTE: discarding redo for group \S+ disk \S+--0
NOTE: disk \S+ \(.*\) in group \S+ \(.*\) is locally offline for writes--0
NOTE: disk \S+ had \S+ error--0
NOTE: disk validation pending for \S+ \S+ in group \S+ \(.*\)--0
NOTE: diskgroup must now \S+ re-mounted prior to first use--0
NOTE: diskgroup resource \S+ is \S+--0
NOTE: diskgroup resource \S+ state is update
NOTE: enlarging \S+ to \S+ threads for group \S+ \(.*\)--0
NOTE: erasing header \(.*\) on grp \S+ disk \S+--0
NOTE: erasing header on grp \S+ disk \S+--0
NOTE: failed resync of disk group \S+ disks--0
NOTE: force \S+ map free for map id \S+--0
NOTE: found stale ownerid \S+ for client \S+--0
NOTE: get diskgroups to mount for database '.*'--0
NOTE: group \S+ \(.*\) high disk header ckpt advanced to fcn \S+--0
NOTE: group \S+ \S+ \S+ location: disks \S+ \S+ \S+ \S+ \S+ \S+ \S+--0
NOTE: group \S+ \S+ \S+ location: disks \S+ \S+ \S+--0
NOTE: group \S+ \S+ not updated.--0
NOTE: group \S+ \S+ updated.--0
NOTE: group \S+ initial \S+ location: disks \S+ \S+ \S+ \S+ \S+ \S+ \S+--0
NOTE: group \S+ initial \S+ location: disks \S+ \S+ \S+ \S+ \S+
NOTE: group \S+ initial \S+ location: disks \S+ \S+ \S+--0
NOTE: group \S+ initial \S+ location: disks \S+ \S+--0
NOTE: group \S+ initial \S+ location: disks \S+--0
NOTE: group \S+ updated \S+ location: disks \S+ \S+ \S+ \S+ \S+ \S+ \S+--0
NOTE: group \S+ updated \S+ location: disks \S+ \S+ \S+ \S+ \S+ \S+--0
NOTE: group \S+ updated \S+ location: disks \S+ \S+ \S+ \S+ \S+--0
NOTE: group \S+ updated \S+ location: disks \S+ \S+ \S+ \S+--0
NOTE: group \S+ updated \S+ location: disks \S+ \S+ \S+--0
NOTE: group \S+ updated \S+ location: disks \S+ \S+--0
NOTE: grp \S+ disk \S+ expelled from the \S+--0
NOTE: halting all I/Os to diskgroup \S+ \(.*\)--0
NOTE: header on disk \S+ advanced to format #2 using fcn \S+--0
NOTE: initial disk modes for disk \S+ \(.*\) in group \S+ \(.*\) is not completely online: modes \S+ lflags \S+--0
NOTE: initializing header \(.*\) on grp \S+ disk \S+--0
NOTE: initializing header on grp \S+ disk \S+--0
NOTE: initiating \S+ startup--0
NOTE: initiating \S+ update: grp \S+ \(.*\), dsk = \S+ mask = \S+ op = \S+ mandatory--0
NOTE: initiating \S+ update: grp = \S+--0
NOTE: initiating client \[.*\] discovery for group \S+ \(.*\)--0
NOTE: initiating dirty detach from lock domain \S+--0
NOTE: initiating resync of disk group \S+ disks--0
NOTE: instance recovery of group \S+ will recover \S+ \S+ \S+ \S+ \S+--0
NOTE: killing foreground for client \S+ \(.*\) due to reconnect of same client id \S+ to \S+ \S+ .*
NOTE: membership refresh pending for group \S+ \(.*\)--0
NOTE: messaging \S+ to quiesce pins Unix process pid: \S+ image: \S+ \(.*\)--0
NOTE: messaging \S+ to quiesce pins Unix process pid: \S+ image: \S+--0
NOTE: ospid \S+ initiating cluster wide offline of disk \S+ in group \S+--0
NOTE: ospid \S+ initiating cluster wide offline of disks \S+ and \S+ in group \S+--0
NOTE: parameter \S+ not allowed in \S+ appliance; overriding \S+ to ".*"
NOTE: process \S+ \(.*\) initiating offline of disk \S+ \(.*\) with mask \S+ in group \S+ \(.*\) \S+ client assisting--0
NOTE: rebalance interrupted for group \S+ \(.*\)--0
NOTE: recovering disk \S+ in diskgroup \S+ \(.*\) after \S+ failed disk online--0
NOTE: redo buffer size is \S+ blocks \(.*\)--0
NOTE: registered owner id \S+ for \S+ \(.*\)--0
NOTE: registered owner id \S+ for \S+--0
NOTE: registering \S+ \[.*\] for client \S+ \S+ ospid \S+--0
NOTE: released resources held for \S+ \S+--0
NOTE: released resources held for client id \S+ \(.*\)--0
NOTE: relocating client \S+ \(.*\) to its local instance; \S+ Instances up message from node \S+ \(.*\).
NOTE: relocating client \S+ \(.*\) to its local instance; Message from node \S+ - \S+ Instance \S+ is \S+--0
NOTE: relocating client \S+ \(.*\) to local instance; \S+ Instance \S+ up message from node \S+--0
NOTE: relocating client \S+ \(.*\)--0
NOTE: relocation enqueue is busy
NOTE: remote asm mode is \S+ \(.*\)--0
NOTE: removing stale \S+ \S+ for client \S+ \(.*\)--0
NOTE: reopening \S+ disks for group \S+--0
NOTE: repairing extent \S+ of file \S+ group \S+--0
NOTE: requesting \S+ \S+ \S+ for \S+--0
NOTE: reset timers for disk: \S+--0
NOTE: running client discovery for group \S+ \(.*\)--0
NOTE: sending set offline flag message \(.*\) to \S+ disk\(.*\) in group \S+
NOTE: set version \S+ for asmCompat \S+ for group \S+--0
NOTE: setting \S+ start \S+ for group \S+ thread \S+ to \S+--0
NOTE: skipping rediscovery for group \S+ \(.*\) on local instance.--0
NOTE: starting \S+ \S+--0
NOTE: starting check of diskgroup \S+
NOTE: starting process \S+
NOTE: starting rebalance of group \S+ \(.*\) at power \S+--0
NOTE: stopping process \S+--0
NOTE: successfully wrote at least one mirror side for diskgroup \S+--0
NOTE: timeout \(.*\) expired for orphan ownerid \S+ for client \S+ \S+ elapsed--0
NOTE: umbilicus traces dumped to \S+--0
NOTE: unable to offline disks after getting write error for diskgroup \S+--0
NOTE: unable to write any mirror side for diskgroup \S+--0
NOTE: unpublish fenced orphan ownerid \S+ for client \S+
NOTE: updated gpnp profile \S+ \S+ .*
NOTE: updated gpnp profile \S+ \S+ to \S+--0
NOTE: updating disk modes to \S+ from \S+ for disk \S+ \(.*\) in group \S+ \(.*\): lflags \S+    --0
NOTE: volume resource \S+ is \S+--0
NOTE: voting file allocation \(.*\) on grp \S+ disk \S+--0
NOTE: voting file allocation on grp \S+ disk \S+--0
NOTE: voting file deletion \(.*\) on grp \S+ disk \S+--0
NOTE: voting file deletion on grp \S+ disk \S+--0
NOTE: waiting for instance recovery of group \S+--0
NOTE: will remove stale ownerid \S+ for client .* \(.*\)--0
NOTE: write to disk \S+ succeeded--0
NOTE:Waiting for all pending writes to complete before de-registering: grpnum \S+--0
NUMA system with \S+ nodes detected--0
Nested reconfiguration detected.--0
Network Resource Management enabled for Process \S+ \(.*\) for Exadata I/O--0
New Low - High Load Threshold Range = \[.*\]--0
New instances \(.*\) \S+--0
No Cluster Synchronization Service reconfig event in \S+ seconds--0
No connectivity to instances: \S+
No connectivity to other instances in the cluster during startup. Hence, \S+ is terminating the instance. Please check the \S+ trace file for details. Also, please check the network logs of this instance along with clusterwide network health for problems and then re-start this instance.
No label in disk \S+--0
No patches have been applied--0
Node \S+--0
Non-local Process blocks cleaned out--0
Number of processor \S+ in the system is \S+--0
OCR_RWSSN0607
OCR_VD_FLEX
OCR_VD_NORMAL
ORA-00445: background process ".*" did not start after \S+ seconds--0
ORA-00453: backgroud process '.*' is \S+--0
ORA-00481: \S+ process terminated with error--0
ORA-00493: \S+ process terminated with error--0
ORA-00600: internal error code, arguments: \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\], \[.*\]--0
ORA-00603: \S+ server session terminated by fatal error
ORA-00604: error occurred at recursive \S+ level \S+--0
ORA-03113: \S+ on communication channel--0
ORA-06512: at ".*", line \S+--0
ORA-06512: at line \S+--0
ORA-07274: spdcr: access error, access to oracle denied.--0
ORA-07445: exception encountered: core dump \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\]--0
ORA-1092 \S+ opitsk aborting process--0
ORA-15001: diskgroup ".*" does not exist or is not mounted--0
ORA-15003: diskgroup ".*" already mounted in another lock name space
ORA-15013: diskgroup ".*" is already mounted--0
ORA-15017: diskgroup ".*" cannot \S+ mounted--0
ORA-15018: diskgroup cannot \S+ created--0
ORA-15020: discovered duplicate \S+ disk ".*"--0
ORA-15027: active use of diskgroup ".*" precludes its dismount--0
ORA-15028: \S+ file '.*' not dropped; currently being accessed--0
ORA-15029: disk '.*' is already mounted by this instance--0
ORA-15031: disk specification '.*' matches no disks--0
ORA-15032: not all alterations performed--0
ORA-15033: disk '.*' belongs to diskgroup ".*"--0
ORA-15040: diskgroup is incomplete--0
ORA-15041: diskgroup ".*" space exhausted--0
ORA-15042: \S+ disk ".*" is missing from group number ".*"--0
ORA-15054: disk ".*" does not exist in diskgroup ".*"--0
ORA-15062: \S+ disk is globally closed--0
ORA-15063: \S+ discovered an insufficient number of disks for diskgroup ".*"--0
ORA-15066: offlining disk ".*" in group ".*" may result in \S+ data loss--0
ORA-15067: command or option incompatible with diskgroup redundancy--0
ORA-15075: disk \S+ is not visible on instance number \S+--0
ORA-15078: \S+ diskgroup was forcibly dismounted--0
ORA-15079: \S+ file is closed
ORA-15080: synchronous I/O operation failed to read block \S+ of disk \S+ in disk group \S+
ORA-15080: synchronous I/O operation failed to read block \S+ of disk \S+ in disk group--0
ORA-15080: synchronous I/O operation failed to write block \S+ of disk \S+ in disk group \S+--0
ORA-15081: failed to submit an I/O operation to \S+ disk--0
ORA-15090: handle \S+ is not \S+ valid descriptor--0
ORA-15130: diskgroup ".*" is being dismounted--0
ORA-15133: instance recovery required for diskgroup \S+--0
ORA-15137: The \S+ cluster is in rolling patch state.
ORA-15173: entry '.*' does not exist in directory '.*'--0
ORA-15186: \S+ error \S+--0
ORA-15186: \S+ error function = .*
ORA-15186: \S+ error function = \[.*\], \s*\S+
ORA-15186: \S+ error function = \[.*\],  error = .*--0
ORA-15186: \S+ error function = \[.*\],  error = \[.*\],  mesg = \[.*\]--0
ORA-15186: \S+ error function = \[.*\],  err--0
ORA-15245: \S+ disk \S+ is already online or being brought online.--0
ORA-15260: permission denied on \S+ disk group
ORA-15268: internal Oracle file \S+ already exists.--0
ORA-15274: Not enough failgroups \(.*\) to create voting files
ORA-15277: disk \S+ is \S+ quorum disk--0
ORA-15283: \S+ operation requires compatible.rdbms of \S+ or higher--0
ORA-15291: \S+ could not \S+ disk ".*" to disk group ".*"--0
ORA-15309: could not access database \S+ in \S+ instance
ORA-15315: Write errors in disk group \S+ could lead to inconsistent \S+ metadata.--0
ORA-15326: specified input \S+ is \S+ not an \S+ file--0
ORA-15340: unable to create member cluster '.*'
ORA-15341: unable to delete member cluster '.*'
ORA-15344: client \S+ not found--0
ORA-15365: member cluster '.*' already configured
ORA-15367: member cluster '.*' not configured
ORA-15416: \S+ disk \S+ in disk group \S+ is offline.--0
ORA-15460: volume name '.*' is already in use
ORA-15463: volume size of \S+ is less than the minimum of \S+
ORA-15466: volume '.*' in disk group '.*' does not exist
ORA-15468: volume '.*' in diskgroup '.*' is currently being accessed
ORA-15477: cannot communicate with the volume driver
ORA-17502: \S+ Failed to create file \S+--0
ORA-17503: \S+ Failed to open file \S+
ORA-27061: waiting for \S+--0
ORA-27061: waiting for async I/Os failed--0
ORA-27072: File I/O error--0
ORA-27300: \S+ system dependent \S+ failed with status: \S+
ORA-27301: \S+ failure message: Cannot assign requested address
ORA-27301: \S+ failure message: Error \S+
ORA-27302: failure occurred at: \S+
ORA-27303: additional information: requested interface \S+ not found. Check output from ifconfig command
ORA-27501: \S+ error creating \S+ port
ORA-27504: \S+ error creating \S+ context
ORA-29701 .*
ORA-29701 \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\] \[.*\]--0
ORA-29701: unable to connect to Cluster Synchronization Service--0
ORA-29702 .*
ORA-29702: error occurred in Cluster Group Service operation--0
ORA-29709 .*
ORA-29709: Communication failure with Cluster Synchronization Services--0
ORA-29710 .*
ORA-29710: Current operation aborted by Cluster Synchronization Services--0
ORA-29740: evicted by instance number \S+ group incarnation \S+
ORA-29746 .*
ORA-29746: Cluster Synchronization Service is being shut down.--0
ORA-29771: process \S+ \(.*\) blocks \S+ \(.*\) for more than \S+ seconds
ORA-488 .*
ORA-493 .*
ORA-56841: Master Diskmon cannot connect to \S+ \S+--0
ORA-56864: Master Diskmon ".*" operation cannot complete because of \S+ \S+ network error--0
ORA-59001: Disk '.*' must \S+ online before disk '.*'.--0
ORA-59703: Inconsistent site information in disk '.*'--0
ORA-59706: The specified allocation unit size '.*' is less than the minimum required for extended disk groups.--0
ORA-59709: No site identified for the disk \S+--0
ORA-59709: No site identified for the disk--0
ORA-59710: site information mismatch between disk group \S+ and disk /dev/asmdisk/3par108--0
ORA-59711: The site identified by \S+ '.*' does not exist.--0
ORA-59716: dropping all disks of the quorum site is not allowed--0
ORA-7274 .*
ORACLE_BASE from environment = \S+--0
ORACLE_BASE value has been saved for future startups--0
ORACLE_HOME = \S+
ORACLE_HOME: \s*\S+--0
OS Pid: \S+ executed alter system set events '.*'--0
OS ping to \S+ \S+ has \S+
Oracle Bequeath \S+ Protocol Adapter for Linux: Version \S+ - \S+
Oracle Database \S+ Enterprise Edition Release \S+ - 64bit \S+--0
Oracle Database \S+ Enterprise Edition Release \S+ - Development
Oracle instance running with \S+ Oracle Direct \S+ \S+ Library Version \S+--0
PAGESIZE  AVAILABLE_PAGES  EXPECTED_PAGES  ALLOCATED_PAGES  ERROR\(.*\)--0
PING started with \S+ \S+ \S+--0
PMAN started with \S+ \S+ \S+--0
PMON \(.*\): terminating the instance due to \S+ error \S+--0
PMON \(.*\): terminating the instance due to error \S+--0
PMON started with \S+ \S+ \S+--0
PSP0 started with \S+ \S+ \S+--0
PXMN started with \S+ \S+ \S+--0
Per process system memlock \(.*\) limit = \S+--0
Performing system state dump.--0
Picked latch-free \S+ scheme \S+
Please \S+ the \S+ \S+ file for more \S+
Please check \S+ trace file for more detail.
Please check instance .*
Please check instance \S+ alert and \S+ trace files for detail.--0
Please check the \S+ log file for more \S+--0
Please refer at \S+ trace file for details.--0
Please refer to \S+ in \S+ note #1274318.1--0
Please see \S+ and oraping trace files for details.--0
Post \S+ to start 1st pass \S+--0
Private Interface '.*' configured from GPnP for use as \S+ private interconnect.
Process \S+ died, see its trace file--0
Process \S+--0
Process termination requested for pid \S+ \[.*\], \[.*\] \[.*\]--0
Processes \S+ and \S+ may \S+ blocked while \S+ performs thread mount.--0
Public Interface '.*' configured from GPnP for use as \S+ public interface.
RBAL \(.*\): terminating the instance due to \S+ error \S+--0
RBAL \(.*\): terminating the instance due to error \S+--0
RBAL started with \S+ \S+ \S+--0
REBALANCE \S+--0
RECOMMENDATION:--0
RECO
REDO
RMON started with \S+ \S+ \S+
Read failed for disk \S+ errno \S+--0
Reason for not supporting certain system pagesizes:--0
Received an instance abort message from instance \S+--0
Received detach msg from inst \S+ for dom \S+--0
Received dirty detach msg from inst \S+ for dom \S+--0
Receiver: inst \S+ binc \S+ ospid \S+--0
Reconfiguration \S+ \(.*\)--0
Release:	2.6.39-400.245.1.el6uek.x86_64--0
Release:	2.6.39-400.246.1.el6uek.x86_64--0
Release:	2.6.39-400.248.3.el6uek.x86_64--0
Release:	2.6.39-400.277.1.el6uek.x86_64--0
Release:	3.8.13-118.13.3.el7uek.x86_64
Release:	3.8.13-118.18.4.el7uek.x86_64
Release:	3.8.13-68.3.4.el6uek.x86_64
Release:	4.1.12-103.3.8.1.el6uek.x86_64
Release:	4.1.12-32.2.3.el7uek.x86_64
Release:	4.1.12-61.1.16.el6uek.x86_64
Release:	4.1.12-61.1.16.el7uek.x86_64
Release:	4.1.12-61.1.27.el7uek.x86_64
Release:	4.1.12-94.4.1.el6uek.x86_64
Remote instance kill is issued with system inc \S+--0
Remote instance kill map \(.*\) \S+ \S+ \S+--0
Remote instance kill map \(.*\) \S+ \S+--0
Restarting \S+ background process \S+--0
SHARED \S+ \S+ \(.*\) into memory: \S+--0
SHUTDOWN: waiting for detached processes '.*' to terminate.--0
SITE \S+  FAILGROUP \S+  DISK '.*' \S+ \S+--0
SITE \S+  QUORUM  FAILGROUP \S+  DISK '.*' \S+ \S+  SIZE \S+--0
SITE siteQ  QUORUM  FAILGROUP \S+  DISK '.*' \S+ \S+--0
SITE sitea  FAILGROUP \S+  DISK '.*' \S+ \S+  SIZE \S+--0
SITE sitea  FAILGROUP \S+  DISK '.*' \S+ \S+--0
SITE sitea  FAILGROUP fg1  DISK '.*' \S+ disk1  SIZE \S+--0
SITE sitea  FAILGROUP fg2  DISK '.*' \S+ \S+--0
SITE sitea  FAILGROUP fg2  DISK '.*' \S+ disk2  SIZE \S+--0
SITE sitea  FAILGROUP fg3  DISK '.*' \S+ \S+--0
SITE sitea  FAILGROUP fg3  DISK '.*' \S+ disk3  SIZE \S+--0
SITE siteb  DISK '.*' \S+ \S+--0
SITE siteb  FAILGROUP \S+  DISK '.*' \S+ \S+  SIZE \S+--0
SITE siteb  FAILGROUP \S+  DISK '.*' \S+ \S+--0
SITE siteq  QUORUM  FAILGROUP \S+  DISK '.*' \S+ \S+--0
SITE siteq  QUORUM  FAILGROUP \S+  DISK '.*' \S+ ted7  SIZE \S+--0
SITE siteq  QUORUM  FAILGROUP su7  DISK '.*' \S+ \S+--0
SITE siteq  QUORUM  FAILGROUP ted7  DISK '.*' \S+ ted7  SIZE \S+--0
SKGXP: ospid \S+ For past \S+ secs network interface query failed for \S+ address \S+ it is being marked as down
SKGXP: ospid \S+ network interface with \S+ address \S+ is \S+
SKGXP: ospid \S+ network interface with \S+ address \S+ is now \S+
SKGXP: ospid \S+ network interface with \S+ address \S+ no longer running \(.*\)
SMON started with \S+ \S+ \S+--0
SQL> \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./--0
SQL> \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./
SQL> \S+ \S+ \S+ \S+ \S+ \S+ \S+
SQL> \S+ \S+ \S+ \S+ \S+ \S+ /. asm agent .//. \{.*\} .//. \S+
SQL> \S+ \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+ ,
SQL> \S+ \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+--0
SQL> \S+ \S+ \S+ \S+ \S+  DISK '.*' \S+ '.*'='.*','.*'='.*' /. \S+ ./
SQL> \S+ \S+ \S+ \S+ \S+  DISK '.*',
SQL> \S+ \S+ \S+ \S+ \S+ fu \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./
SQL> \S+ \S+ \S+ \S+ \S+ mc1exp1 \S+ \S+ /. \S+ ./
SQL> \S+ \S+ \S+ \S+ \s*\S* asm agent .//. \{.*\} ./
SQL> \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+
SQL> \S+ \S+ \S+ \S+  DISK '.*'
SQL> \S+ \S+ \S+ \S+  FORCE  /. asm agent .//. \{.*\} ./--0
SQL> \S+ \S+ \S+ \S+ /. asm agent call crs .//. \{.*\} ./--0
SQL> \S+ \S+ \S+ \S+
SQL> \S+ \S+ \S+ set attribute '.*'='.*'
SQL> \S+ \S+ Flash \S+ \S+ \S+ \S+ \S+ /. \S+ ./
SQL>  ALTER \S+ \S+ \S+  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ .* \S+ \S+ \S+ \S+ '.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ .* \S+ .* \S+ .* \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ .* \S+ .* \S+ .* \S+ .* \S+ .* \S+ .* \S+ .* \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ HDD_E0_S04_1744837980p2,'.*' \S+ HDD_E0_S07_1744841556p2,'.*' \S+ HDD_E0_S01_1744842656p2,'.*' \S+ HDD_E0_S11_1744843004p2,'.*' \S+ HDD_E0_S08_1744843332p2,'.*' \S+ HDD_E0_S05_1744844224p2,'.*' \S+ HDD_E0_S02_1744851028p2,'.*' \S+ HDD_E0_S03_1744852972p2,'.*' \S+ HDD_E0_S12_1744858868p2,'.*' \S+ HDD_E0_S14_1744859716p2,'.*' \S+ HDD_E0_S06_1744863188p2,'.*' \S+ HDD_E0_S13_1744866148p2,'.*' \S+ HDD_E0_S00_1744867212p2,'.*' \S+ HDD_E0_S10_1744878688p2,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ HDD_E1_S00_1744842792p2,'.*' \S+ HDD_E0_S07_1744850800p2,'.*' \S+ HDD_E0_S01_1744853576p2,'.*' \S+ HDD_E1_S09_1744853672p2,'.*' \S+ HDD_E0_S06_1744857856p2,'.*' \S+ HDD_E1_S11_1744858132p2,'.*' \S+ HDD_E1_S06_1744861896p2,'.*' \S+ HDD_E1_S04_1744862664p2,'.*' \S+ HDD_E0_S04_1744863140p2,'.*' \S+ HDD_E0_S11_1744864844p2,'.*' \S+ HDD_E0_S14_1744866828p2,'.*' \S+ HDD_E0_S00_1744867016p2,'.*' \S+ HDD_E1_S02_1744867536p2,'.*' \S+ HDD_E1_S12_1744868828p2,'.*' \S+ HDD_E1_S07_1744870152p2,'.*' \S+ HDD_E1_S14_1744870360p2,'.*' \S+ HDD_E0_S10_1744870716p2,'.*' \S+ HDD_E0_S05_1744871144p2,'.*' \S+ HDD_E0_S13_1744871176p2,'.*' \S+ HDD_E0_S08_1744871256p2,'.*' \S+ HDD_E1_S03_1744871404p2,'.*' \S+ HDD_E0_S02_1744872960p2,'.*' \S+ HDD_E1_S13_1744874592p2,'.*' \S+ HDD_E0_S09_1744874692p2,'.*' \S+ HDD_E1_S05_1744875028p2,'.*' \S+ HDD_E0_S12_1744876192p2,'.*' \S+ HDD_E0_S03_1744876196p2,'.*' \S+ HDD_E1_S10_1744876600p2,'.*' \S+ HDD_E1_S01_1744878672p2,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S00_2348897752p2,'.*' \S+ SSD_E0_S18_2348898964p2,'.*' \S+ SSD_E0_S04_2348900212p2,'.*' \S+ SSD_E0_S10_2348900404p2,'.*' \S+ SSD_E0_S14_2348900412p2,'.*' \S+ SSD_E0_S03_2348900444p2,'.*' \S+ SSD_E0_S07_2348901252p2,'.*' \S+ SSD_E0_S05_2348901264p2,'.*' \S+ SSD_E0_S11_2348901272p2,'.*' \S+ SSD_E0_S13_2348901276p2,'.*' \S+ SSD_E0_S08_2348901316p2,'.*' \S+ SSD_E0_S02_2348901664p2,'.*' \S+ SSD_E0_S12_2348902336p2,'.*' \S+ SSD_E0_S16_2348902352p2,'.*' \S+ SSD_E0_S19_2348903216p2,'.*' \S+ SSD_E0_S09_2348903248p2,'.*' \S+ SSD_E0_S01_2348903252p2,'.*' \S+ SSD_E0_S15_2348903276p2,'.*' \S+ SSD_E0_S06_2348903380p2,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S03_2348837848p2,'.*' \S+ SSD_E0_S00_2348839088p2,'.*' \S+ SSD_E0_S05_2348839320p2,'.*' \S+ SSD_E1_S04_2348870648p2,'.*' \S+ SSD_E1_S08_2348897684p2,'.*' \S+ SSD_E1_S14_2348898452p2,'.*' \S+ SSD_E1_S10_2348898716p2,'.*' \S+ SSD_E1_S19_2348898872p2,'.*' \S+ SSD_E0_S07_2348899624p2,'.*' \S+ SSD_E1_S13_2348899748p2,'.*' \S+ SSD_E1_S16_2348899812p2,'.*' \S+ SSD_E0_S02_2348899900p2,'.*' \S+ SSD_E0_S04_2348900068p2,'.*' \S+ SSD_E0_S09_2348900076p2,'.*' \S+ SSD_E0_S01_2348900140p2,'.*' \S+ SSD_E0_S19_2348900216p2,'.*' \S+ SSD_E0_S10_2348900220p2,'.*' \S+ SSD_E0_S16_2348900316p2,'.*' \S+ SSD_E0_S17_2348900464p2,'.*' \S+ SSD_E1_S03_2348900664p2,'.*' \S+ SSD_E0_S11_2348900720p2,'.*' \S+ SSD_E0_S15_2348900752p2,'.*' \S+ SSD_E1_S01_2348901068p2,'.*' \S+ SSD_E0_S14_2348901280p2,'.*' \S+ SSD_E0_S13_2348901552p2,'.*' \S+ SSD_E1_S09_2348901804p2,'.*' \S+ SSD_E0_S12_2348901868p2,'.*' \S+ SSD_E1_S02_2348901940p2,'.*' \S+ SSD_E1_S15_2348902168p2,'.*' \S+ SSD_E1_S17_2348902212p2,'.*' \S+ SSD_E1_S11_2348902372p2,'.*' \S+ SSD_E1_S00_2348902420p2,'.*' \S+ SSD_E0_S18_2348902444p2,'.*' \S+ \S+
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S16_2348897652p1,'.*' \S+ SSD_E0_S17_2348897688p1,'.*' \S+ SSD_E1_S16_2348898880p1,'.*' \S+ SSD_E1_S15_2348898952p1,'.*' \S+ SSD_E1_S18_2348899284p1,'.*' \S+ SSD_E0_S15_2348901548p1,'.*' \S+ SSD_E1_S17_2348901824p1,'.*' \S+ SSD_E0_S18_2348901988p1,'.*' \S+ SSD_E0_S19_2348902428p1,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S18_2348899732p1,'.*' \S+ SSD_E0_S16_2348902216p1,'.*' \S+ SSD_E0_S17_2348902424p1,'.*' \S+ SSD_E0_S15_2348902756p1,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'  
SQL>  alter diskgroup \S+ set attribute '.*' = '.*'  
SQL> /. \S+ ./ALTER \S+ \S+ \S+ \S+ \S+ \S+
SQL> /. \S+ ./ALTER \S+ \S+ \S+ \S+ \S+
SQL> /. \S+ ./ALTER \S+ \S+ \S+ \s*\S*
SQL> /. \S+ ./DROP \S+ \S+ \S+ \S+ \S+  
SQL> /. \S+ ./alter diskgroup \S+ \S+ volume '.*' size \S+
SQL> /. \S+ ./alter diskgroup \S+  drop  disk \S+  
SQL> /. \S+ ./alter diskgroup \S+ drop volume '.*'
SQL> /. \S+ ./alter diskgroup /.ASMCMD./ ".*" \S+ directory '.*'
SQL> /. \S+ ./alter diskgroup /.ASMCMD./ ".*" drop directory '.*' force
SQL> /. \S+ ./alter diskgroup Data drop volume '.*'
SQL> /. \S+ ./alter diskgroup dg02 \S+ volume '.*' size \S+
SQL> /. \S+ ./alter diskgroup dg02 drop volume '.*'
SQL> /. \S+ ./alter diskgroup dg03 \S+ volume '.*' size \S+
SQL> /. \S+ ./alter diskgroup dg03 drop volume '.*'
SQL> /. \S+ ./alter diskgroup dg04 \S+ volume '.*' size \S+
SQL> /. \S+ ./alter diskgroup dg04 drop volume '.*'
SQL> /. \S+ ./alter diskgroup mmdg \S+ volume '.*' size \S+
SQL> /. \S+ ./alter diskgroup pri drop volume '.*'
SQL> /. \S+ ./alter diskgroup resize01 \S+ volume '.*' size \S+
SQL> /. asm agent ./
SQL> alter diskgroup \S+ \S+ \S+ \S+ \S+ \S+ ./
SQL> alter diskgroup \S+ \S+ \S+ '.*'
SQL> alter diskgroup \S+ \S+--0
SQL> alter diskgroup \S+ set attribute '.*' = '.*'  
SQL> alter diskgroup \S+ set attribute '.*' = '.*' /. \S+ ./
SQL> alter diskgroup \S+ set attribute '.*' = '.*'
SQL> alter diskgroup MGMTrhps \S+ directory '.*'
SQL> alter diskgroup MGMTrhps set attribute '.*' = '.*'
SQL> alter diskgroup dg04 \S+ disk \S+
SQL> alter diskgroup gidg set attribute '.*' = '.*' /. \S+ ./
SQL> alter diskgroup mmdg \S+ directory '.*'
SQL> create diskgroup \S+ \S+ \S+  DISK
SQL> create diskgroup \S+ \S+ \S+
SQL> create diskgroup \S+ \S+ redundancy disk .* attribute '.*'='.*','.*'='.*','.*'='.*','.*'='.*'
SQL> drop diskgroup \S+ including contents--0
SUCCESS: \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./--0
SUCCESS: \S+ \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./
SUCCESS: \S+ \S+ \S+ \S+ \S+ \S+ \S+
SUCCESS: \S+ \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+--0
SUCCESS: \S+ \S+ \S+ \S+ \S+ fu \S+ \S+ \S+ \S+ \S+ \S+ \S+ /. \S+ ./
SUCCESS: \S+ \S+ \S+ \S+ \S+ mc1exp1 \S+ \S+ /. \S+ ./
SUCCESS: \S+ \S+ \S+ \S+ \s*\S* asm agent .//. \{.*\} ./
SUCCESS: \S+ \S+ \S+ \S+  DISK '.*' \S+ \S+
SUCCESS: \S+ \S+ \S+ \S+  DISK '.*'
SUCCESS: \S+ \S+ \S+ \S+  FORCE  /. asm agent .//. \{.*\} ./--0
SUCCESS: \S+ \S+ \S+ \S+ /. asm agent call crs .//. \{.*\} ./--0
SUCCESS: \S+ \S+ \S+ \S+
SUCCESS: \S+ \S+ \S+ set attribute '.*'='.*'
SUCCESS: \S+ \S+ Flash \S+ \S+ \S+ \S+ \S+ /. \S+ ./
SUCCESS: \S+ enlarged for group \S+ \(.*\)--0
SUCCESS:  ALTER \S+ \S+ \S+
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ .* \S+ \S+ \S+ \S+ '.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ .* \S+ .* \S+ .* \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ .* \S+ .* \S+ .* \S+ .* \S+ .* \S+ .* \S+ .* \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ HDD_E0_S04_1744837980p2,'.*' \S+ HDD_E0_S07_1744841556p2,'.*' \S+ HDD_E0_S01_1744842656p2,'.*' \S+ HDD_E0_S11_1744843004p2,'.*' \S+ HDD_E0_S08_1744843332p2,'.*' \S+ HDD_E0_S05_1744844224p2,'.*' \S+ HDD_E0_S02_1744851028p2,'.*' \S+ HDD_E0_S03_1744852972p2,'.*' \S+ HDD_E0_S12_1744858868p2,'.*' \S+ HDD_E0_S14_1744859716p2,'.*' \S+ HDD_E0_S06_1744863188p2,'.*' \S+ HDD_E0_S13_1744866148p2,'.*' \S+ HDD_E0_S00_1744867212p2,'.*' \S+ HDD_E0_S10_1744878688p2,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ HDD_E1_S00_1744842792p2,'.*' \S+ HDD_E0_S07_1744850800p2,'.*' \S+ HDD_E0_S01_1744853576p2,'.*' \S+ HDD_E1_S09_1744853672p2,'.*' \S+ HDD_E0_S06_1744857856p2,'.*' \S+ HDD_E1_S11_1744858132p2,'.*' \S+ HDD_E1_S06_1744861896p2,'.*' \S+ HDD_E1_S04_1744862664p2,'.*' \S+ HDD_E0_S04_1744863140p2,'.*' \S+ HDD_E0_S11_1744864844p2,'.*' \S+ HDD_E0_S14_1744866828p2,'.*' \S+ HDD_E0_S00_1744867016p2,'.*' \S+ HDD_E1_S02_1744867536p2,'.*' \S+ HDD_E1_S12_1744868828p2,'.*' \S+ HDD_E1_S07_1744870152p2,'.*' \S+ HDD_E1_S14_1744870360p2,'.*' \S+ HDD_E0_S10_1744870716p2,'.*' \S+ HDD_E0_S05_1744871144p2,'.*' \S+ HDD_E0_S13_1744871176p2,'.*' \S+ HDD_E0_S08_1744871256p2,'.*' \S+ HDD_E1_S03_1744871404p2,'.*' \S+ HDD_E0_S02_1744872960p2,'.*' \S+ HDD_E1_S13_1744874592p2,'.*' \S+ HDD_E0_S09_1744874692p2,'.*' \S+ HDD_E1_S05_1744875028p2,'.*' \S+ HDD_E0_S12_1744876192p2,'.*' \S+ HDD_E0_S03_1744876196p2,'.*' \S+ HDD_E1_S10_1744876600p2,'.*' \S+ HDD_E1_S01_1744878672p2,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S00_2348897752p2,'.*' \S+ SSD_E0_S18_2348898964p2,'.*' \S+ SSD_E0_S04_2348900212p2,'.*' \S+ SSD_E0_S10_2348900404p2,'.*' \S+ SSD_E0_S14_2348900412p2,'.*' \S+ SSD_E0_S03_2348900444p2,'.*' \S+ SSD_E0_S07_2348901252p2,'.*' \S+ SSD_E0_S05_2348901264p2,'.*' \S+ SSD_E0_S11_2348901272p2,'.*' \S+ SSD_E0_S13_2348901276p2,'.*' \S+ SSD_E0_S08_2348901316p2,'.*' \S+ SSD_E0_S02_2348901664p2,'.*' \S+ SSD_E0_S12_2348902336p2,'.*' \S+ SSD_E0_S16_2348902352p2,'.*' \S+ SSD_E0_S19_2348903216p2,'.*' \S+ SSD_E0_S09_2348903248p2,'.*' \S+ SSD_E0_S01_2348903252p2,'.*' \S+ SSD_E0_S15_2348903276p2,'.*' \S+ SSD_E0_S06_2348903380p2,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S03_2348837848p2,'.*' \S+ SSD_E0_S00_2348839088p2,'.*' \S+ SSD_E0_S05_2348839320p2,'.*' \S+ SSD_E1_S04_2348870648p2,'.*' \S+ SSD_E1_S08_2348897684p2,'.*' \S+ SSD_E1_S14_2348898452p2,'.*' \S+ SSD_E1_S10_2348898716p2,'.*' \S+ SSD_E1_S19_2348898872p2,'.*' \S+ SSD_E0_S07_2348899624p2,'.*' \S+ SSD_E1_S13_2348899748p2,'.*' \S+ SSD_E1_S16_2348899812p2,'.*' \S+ SSD_E0_S02_2348899900p2,'.*' \S+ SSD_E0_S04_2348900068p2,'.*' \S+ SSD_E0_S09_2348900076p2,'.*' \S+ SSD_E0_S01_2348900140p2,'.*' \S+ SSD_E0_S19_2348900216p2,'.*' \S+ SSD_E0_S10_2348900220p2,'.*' \S+ SSD_E0_S16_2348900316p2,'.*' \S+ SSD_E0_S17_2348900464p2,'.*' \S+ SSD_E1_S03_2348900664p2,'.*' \S+ SSD_E0_S11_2348900720p2,'.*' \S+ SSD_E0_S15_2348900752p2,'.*' \S+ SSD_E1_S01_2348901068p2,'.*' \S+ SSD_E0_S14_2348901280p2,'.*' \S+ SSD_E0_S13_2348901552p2,'.*' \S+ SSD_E1_S09_2348901804p2,'.*' \S+ SSD_E0_S12_2348901868p2,'.*' \S+ SSD_E1_S02_2348901940p2,'.*' \S+ SSD_E1_S15_2348902168p2,'.*' \S+ SSD_E1_S17_2348902212p2,'.*' \S+ SSD_E1_S11_2348902372p2,'.*' \S+ SSD_E1_S00_2348902420p2,'.*' \S+ SSD_E0_S18_2348902444p2,'.*' \S+ \S+
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S16_2348897652p1,'.*' \S+ SSD_E0_S17_2348897688p1,'.*' \S+ SSD_E1_S16_2348898880p1,'.*' \S+ SSD_E1_S15_2348898952p1,'.*' \S+ SSD_E1_S18_2348899284p1,'.*' \S+ SSD_E0_S15_2348901548p1,'.*' \S+ SSD_E1_S17_2348901824p1,'.*' \S+ SSD_E0_S18_2348901988p1,'.*' \S+ SSD_E0_S19_2348902428p1,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  CREATE \S+ \S+ \S+ \S+ \S+ '.*' \S+ SSD_E0_S18_2348899732p1,'.*' \S+ SSD_E0_S16_2348902216p1,'.*' \S+ SSD_E0_S17_2348902424p1,'.*' \S+ SSD_E0_S15_2348902756p1,'.*' \S+ \S+ \S+ '.*' = '.*' , '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*', '.*' = '.*'
SUCCESS:  alter diskgroup \S+ set attribute '.*' = '.*'
SUCCESS: /. \S+ ./ALTER \S+ \S+ \S+ \S+ \S+ \S+
SUCCESS: /. \S+ ./ALTER \S+ \S+ \S+ \S+ \S+
SUCCESS: /. \S+ ./ALTER \S+ \S+ \S+ \s*\S+
SUCCESS: /. \S+ ./DROP \S+ \S+ \S+ \S+ \S+
SUCCESS: /. \S+ ./alter diskgroup \S+ \S+ volume '.*' size \S+
SUCCESS: /. \S+ ./alter diskgroup \S+ \s*\S+ \s*\S+ .*
SUCCESS: /. \S+ ./alter diskgroup /.ASMCMD./ ".*" \S+ directory '.*'
SUCCESS: /. \S+ ./alter diskgroup /.ASMCMD./ ".*" drop directory '.*' force
SUCCESS: /. \S+ ./alter diskgroup Data drop volume '.*'
SUCCESS: /. \S+ ./alter diskgroup dg02 \S+ volume '.*' size \S+
SUCCESS: /. \S+ ./alter diskgroup dg02 drop volume '.*'
SUCCESS: /. \S+ ./alter diskgroup dg03 \S+ volume '.*' size \S+
SUCCESS: /. \S+ ./alter diskgroup dg03 drop volume '.*'
SUCCESS: /. \S+ ./alter diskgroup dg04 \S+ volume '.*' size \S+
SUCCESS: /. \S+ ./alter diskgroup dg04 drop volume '.*'
SUCCESS: /. \S+ ./alter diskgroup mmdg \S+ volume '.*' size \S+
SUCCESS: /. \S+ ./alter diskgroup pri drop volume '.*'
SUCCESS: /. \S+ ./alter diskgroup resize01 \S+ volume '.*' size \S+
SUCCESS: Advanced \S+ to \S+ for grp \S+
SUCCESS: Exadata diskgroup \S+ was mounted--0
SUCCESS: alter diskgroup \S+ \S+ \S+ \S+ \S+ \S+ ./
SUCCESS: alter diskgroup \S+ \S+ \S+ '.*'--0
SUCCESS: alter diskgroup \S+ \S+--0
SUCCESS: alter diskgroup \S+ set attribute '.*' = '.*' /. \S+ ./
SUCCESS: alter diskgroup \S+ set attribute '.*' = '.*'
SUCCESS: alter diskgroup MGMTrhps \S+ directory '.*'
SUCCESS: alter diskgroup MGMTrhps set attribute '.*' = '.*'
SUCCESS: alter diskgroup dg04 \S+ disk \S+
SUCCESS: alter diskgroup gidg set attribute '.*' = '.*' /. \S+ ./
SUCCESS: alter diskgroup mmdg \S+ directory '.*'
SUCCESS: check of diskgroup \S+ found no errors
SUCCESS: create diskgroup \S+ \S+ \S+  DISK
SUCCESS: create diskgroup \S+ \S+ \S+
SUCCESS: create diskgroup \S+ \S+ redundancy disk .* attribute '.*'='.*','.*'='.*','.*'='.*','.*'='.*'
SUCCESS: diskgroup \S+ was \S+--0
SUCCESS: diskgroup \S+ was force dropped
SUCCESS: drop diskgroup \S+ including contents--0
SUCCESS: grp \S+ disk \S+ emptied--0
SUCCESS: rebalance completed for group \S+ \(.*\)--0
SUCCESS: refreshed membership for \S+ \(.*\)--0
SYS auditing is enabled--0
SZAUD: Cluster class retrieved from \S+ is \[.*\]. thus skipping setting audit syslog level--0
SZAUD: Failed to initialized \S+ \[.*\] \[.*\]--0
Sat Sep \S+ \S+ \S+
Scan count \S+--0
Scanned disk \S+--0
See Note \S+ at My Oracle Support for error and packaging details.--0
Session \S+ \S+ Serial number: \S+--0
Set master node info--0
Shared memory segment for instance monitoring created--0
Shutting down archive processes--0
Shutting down instance \(.*\) \(.*\)--0
Shutting down instance \(.*\)
Shutting down instance: further logons disabled--0
Starting \S+ instance \(.*\) \(.*\)--0
Starting background process \S+--0
Stopping background process \S+--0
Storage:	Exadata--0
Submitted all \S+ remote-cache requests--0
Submitted all remote-enqueue requests--0
Sun Oct \S+ \S+ \S+
Supported system pagesize\(.*\):--0
Suppressed nested communications reconfiguration: \S+ \S+--0
System State dumped to trace file \S+--0
System name:	Linux--0
System parameters with non-default values:--0
System state dump requested by \(.*\), summary=\[.*\]. error - .*
System state dump requested by \(.*\), summary=\[.*\].--0
TCP/IP \S+ Protocol Adapter for Linux: Version \S+ - \S+
TEST--0
TNS for Linux: Version \S+ - \S+
TNS-00515: Connect failed because target host or object does not exist--0
TNS-12535: TNS:operation timed out--0
TNS-12537: TNS:connection closed
TNS-12545: Connect failed because target host or object does not exist--0
The instance eviction \S+ is \S+--0
The instance eviction map is \S+ \S+--0
There are no devices to discover.--0
This would cause some instances to \S+ killed
Thu Oct \S+ \S+ \S+
Time drifts can result in unexpected behavior such as time-outs.
Time: \S+ \S+--0
Tns error struct:--0
Tokenized diskstring \S+--0
Tracing not turned on.--0
Tue Oct \S+ \S+ \S+
USER \(.*\): terminating the instance due to \S+ error \S+--0
USER \(.*\): terminating the instance due to error \S+--0
USER \(.*\): terminating the instance--0
Unexpected return code \(.*\) from the Cluster Synchronization Service \(.*\)--0
Use \S+ or Support Workbench to package the incident.--0
Using \S+ parameter default value as \S+--0
Using default \S+ of \S+ \S+--0
Using parameter settings in client-side pfile \S+ on machine \S+--0
Using parameter settings in client-side pfile--0
Using parameter settings in server-side \S+ \S+--0
VBG0 started with \S+ \S+ \S+
VBG1 started with \S+ \S+ \S+
VBG2 started with \S+ \S+ \S+
VBG3 started with \S+ \S+ \S+
VDBG started with \S+ \S+ \S+
VERSION \S+--0
VKTM reset to run at normal priority--0
VKTM running at \(.*\) precision--0
VKTM running at \(.*\)millisec precision with \S+ quantum \(.*\)ms--0
VKTM started with \S+ \S+ \S+ at elevated \(.*\) priority--0
VKTM started with \S+ \S+ \S+
VM name:	Xen Version: \S+ \(.*\)
VMB0 started with \S+ \S+ \S+
Version \S+--0
Version:	#1 \S+ \S+ \S+ \S+ \S+ \S+ \S+--0
Version:	#2 \S+ \S+ \S+ \S+ \S+ \S+ \S+
WARNING: \(.*\) disk offline and rejecting I/O--0
WARNING: \S+ \S+ addresses should not \S+ used on \S+ engineered systems.--0
WARNING: \S+ disk \S+ not found \(.*\)--0
WARNING: \S+ does not support ipclw. Switching to skgxp--0
WARNING: \S+ failed to obtain \S+ quorum of supporting disks in group \S+ site \S+--0
WARNING: \S+ failed to write \S+ quorum of target disks in group \S+ site \S+ \(.*\)--0
WARNING: \S+ found an alien heartbeat on disk \S+ \(.*\)--0
WARNING: \S+ has insufficient disks to maintain consensus for group \S+ site \S+ Minimum required is \S+ updating \S+ \S+ copies from \S+ total of \S+--0
WARNING: \S+ signaled when performing \S+ block repair for \S+ \S+ \S+--0
WARNING: \S+ unable to close thread \S+ group \S+ \(.*\) due to disconnected client\(.*\) from previous incarnation of \S+ cluster--0
WARNING: Background operations delayed until \S+ \S+ because \S+ was not stopped cleanly and there could \S+ disconnected client\(.*\)--0
WARNING: Change in appliance properties detected during mount of diskgroup \S+
WARNING: Disk \S+ \(.*\) in group \S+ mode \S+ is now being offlined
WARNING: Disk \S+ \(.*\) in group \S+ will \S+ dropped in: \(.*\) secs on \S+ inst \S+--0
WARNING: Disk Group \S+ containing \S+ \S+ is not mounted--0
WARNING: Disk Group \S+ containing spfile for this instance is not mounted--0
WARNING: Found \S+ stale FDs on foreground processes--0
WARNING: Hbeat \S+ to \S+ disk \S+ in group \S+ failed. \[.*\]--0
WARNING: Offline of disk \S+ \(.*\) in group \S+ and mode \S+ failed on \S+ inst \S+--0
WARNING: Older cell \S+ detected: vers \S+
WARNING: Oracle executable binary mismatch detected.--0
WARNING: PST-initiated drop of \S+ disk\(.*\) in group .*--0
WARNING: Read Failed. \S+ \S+ \S+ \S+ \S+--0
WARNING: Site \S+ will \S+ quarantined--0
WARNING: Started Drop Disk Timeout for Disk \S+ \(.*\) in group \S+ with \S+ value \S+--0
WARNING: Waited \S+ secs for write \S+ to \S+ disk \S+ in group \S+--0
WARNING: Write Failed. \S+ \S+ \S+ \S+ \S+--0
WARNING: block repair initiating disk offline--0
WARNING: client \[.*\] cleanup delayed; waited \S+ pid \S+ mbr \S+--0
WARNING: client \[.*\] not responsive for \S+ state=0x1. killing pid \S+
WARNING: could not find \S+ disk--0
WARNING: could not find any \S+ disk in grp \S+--0
WARNING: dirty detached from lock domain \S+--0
WARNING: failed to \S+ diskgroup resource \S+ \(.*\)
WARNING: failed to copy file \S+ extent \S+ disk \S+ au \S+ offset \S+ status \S+--0
WARNING: failed to find state to reconnect client \S+ id \S+ \S+ after \S+ secs--0
WARNING: failed to get diskgroup list for database '.*'--0
WARNING: failed to online diskgroup resource \S+ \(.*\)--0
WARNING: failed to read mirror side \S+ of virtual extent \S+ logical extent \S+ of file \S+ in group \[.*\] from disk \S+  allocation unit \S+ reason error; if possible, will try another mirror side--0
WARNING: failed to update diskgroup resource \S+ \(.*\)--0
WARNING: failed to write mirror side \S+ of virtual extent \S+ logical extent \S+ of file \S+ in group \S+ on disk \S+ allocation unit \S+--0
WARNING: found another non-responsive disk \S+ \(.*\) that will \S+ offlined--0
WARNING: giving up on Remote Cluster client id \S+ \[.*\] which has not reconnected for \S+ seconds \(.*\) \[.*\]
WARNING: giving up on client id \S+ \[.*\] which has not reconnected for \S+ seconds \(.*\) \[.*\]--0
WARNING: group \S+ file \S+ vxn \S+ block \S+ write I/O failed--0
WARNING: grp \S+ all disks in quorum site siteq being dropped.--0
WARNING: grp \S+ disk \S+ still has contents \(.*\)--0
WARNING: inbound connection timed out \(.*\)--0
WARNING: offline disk number \S+ has references \(.*\)--0
WARNING: promoting mount of diskgroup \S+ to force.--0
WARNING: rejecting addition of disk number \S+ to group \S+--0
WARNING: unknown state for diskgroup resource \S+ Return Value: \S+
WARNING: using default parameter settings without any parameter file--0
Waiting for instances to leave: \S+ \S+--0
Waiting for instances to leave: \S+--0
Warning: \S+ detected \S+ \S+ time drift.
Warning: \S+ detected \S+ time stall.
Warning: \S+ processes are still \S+ to shmid \S+
Warning: Oraping detected connectivity issues.--0
With the Real Application Clusters and Automatic Storage Management options.
XDMG started with \S+ \S+ \S+--0
XDWK started with \S+ \S+ \S+--0
afd_discovery string: \S+--0
afdb_getdiscstr: \S+--0
afdb_scandisk: \S+--0
afdt_check_syntax: \S+--0
afdt_errorsLEM: \S+--0
afdt_libinit: \S+--0
allocate domain \S+ valid . \S+--0
alter diskgroup \S+ online disk \S+--0
an eviction is expected due environment issues--0
asm agent .//. \{.*\} .//. \S+--0
asm agent .//. \{.*\} ./--0
asm agent call crs .//. \{.*\} ./--0
asm_diskgroups           = ".*"--0
asm_diskstring           = ".*"--0
asm_power_limit          = \S+--0
audit_syslog_level       = ".*"
cluster guid \(.*\) generated for \S+ Hbeat for instance \S+
cluster interconnect \S+ version: Oracle \S+ \(.*\)--0
dead instance detected - domain \S+ invalid = \S+--0
detach from dom \S+ sending detach message to inst \S+--0
dirty detach - domain \S+ invalid = \S+--0
disk '.*' name \S+ attribute '.*'='.*','.*'='.*','.*'='.*','.*'='.*'
disk '.*' name \S+
disk: \S+ \S+ \S+ file number: \S+ extent: \S+--0
domain \S+ valid = \S+ according to instance \S+--0
event                    = ".*"--0
falling back to sync, expect performance degradation
ferr returned by kgxgnagetferror in kfmsCheckCookie is \s*\S+
force--0
freeing rdom \S+--0
from \S+ to \S+ due to the value of parameter processes \(.*\)
in grp \S+--0
incarnation:\S+ \S+ result:'.*'--0
instance \S+ validates domain \S+--0
instance_number obtained from \S+ = \S+ checking for the existence of node \S+--0
instance_type            = ".*"
issue alter system set ".*" = true to disable these messages--0
kjbdomatt send to inst \S+--0
kjbdomdet send to inst \S+--0
kjidomenacan initialized to \S+--0
ksxp_exafusion_enabled_dcf: \S+--0
kxfpclinfo: \S+ Name server Failed \S+ - Turning Load Balancing Off
kzaac_get_instance_lock: Single instance node. Ismaster = \S+
large_pool_size          = \S+--0
lmon registered with \S+ - instance number \S+ \(.*\)--0
memory_target            = \S+
node \S+ does not exist. \S+ = \S+--0
nowait--0
ns \S+ err code: \S+--0
nt \S+ err code: \S+--0
ontent.type'.*'data.*
opidrv aborting process \S+ ospid \(.*\) as \S+ result of \S+
opiodr aborting process unknown ospid \(.*\) as \S+ result of \S+--0
ossnet_fail_defcon: Giving up on Cell \S+ as retry limit \(.*\) reached.--0
path:\S+--0
path:AFD:DATA1--0
path:AFD:DATA2--0
path:AFD:DATA3--0
path:AFD:DBDG1
path:AFD:GIDG1
path:AFD:GIDG2
path:AFD:GIDG3
path:AFD:MGMT1
path:AFD:MGMT2
path:AFD:MGMT3
path:AFD:OCRDG2--0
path:AFD:OCRDG3--0
path:AFD:SU1--0
path:AFD:SU2--0
path:AFD:SU5--0
path:AFD:SU6--0
path:AFD:TMP11--0
path:Unknown disk--0
path:o/192.168.40.239/CRS_CD_00_nshc01celadm08--0
path:o/192.168.40.239/CRS_CD_02_nshc01celadm08--0
prior to instance startup operation.--0
processes                = \S+
remote_login_passwordfile= ".*"--0
requested by \(.*\), summary=\[.*\]--0
running stat on \S+--0
slave \S+ \(.*\)--0
sskgm_fileget: skipping shmid \S+
start recovery: pdb \S+ passed in flags \S+ \(.*\)--0
subsys:\S+ \S+ \S+ \S+ \S+--0
subsys:OSS \S+ \S+ \S+ osderr2:0x0--0
subsys:System \S+ \S+ \S+ osderr2:0x0--0
to lock 100% of \S+ \S+ \S+ \(.*\) pages into physical memory--0
validate pdb \S+ flags \S+ valid \S+ pdb flags \S+--0
validated domain \S+ flags = \S+--0
